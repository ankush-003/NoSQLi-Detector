{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers datasets evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Huggingface Hub Login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login(token=\"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\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"json\", data_files=\"dataset7.json\")\n",
    "# print(dataset['train'])\n",
    "# print(f\"sample data{dataset['train'][0]}\")\n",
    "train_dataset = load_dataset(\"json\", data_files=\"dataset7.json\", split=\"train[:80%]\")\n",
    "eval_dataset = load_dataset(\"json\", data_files=\"dataset7.json\", split=\"train[80%:90%]\")\n",
    "test_dataset = load_dataset(\"json\", data_files=\"dataset7.json\", split=\"train[90%:]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training dataset:{train_dataset}\")\n",
    "print(f\"Evaluation dataset:{eval_dataset}\")\n",
    "print(f\"Testing dataset:{test_dataset}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True)\n",
    "\n",
    "tokenized_train_dataset = train_dataset.map(preprocess_function, batched=True)\n",
    "tokenized_eval_dataset = eval_dataset.map(preprocess_function, batched=True)\n",
    "tokenized_test_dataset = test_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {0: \"Benign\", 1: \"Malicious\"}\n",
    "label2id = {\"Benign\": 0, \"Malicious\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\", num_labels=2, id2label=id2label, label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"nosql-identifier-distilbert\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=True,\n",
    "    logging_dir=\"./logs\",  # Directory for storing logs\n",
    "    logging_steps=500,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.push_to_hub(\"ankush-003/nosql-identifier-distilbert\")\n",
    "tokenizer.push_to_hub(\"ankush-003/nosql-identifier-distilbert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments, BertTokenizer, BertForSequenceClassification\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import pandas as pd\n",
    "# Load the test dataset\n",
    "# test_dataset = Dataset.load_from_disk(\"path_to_test_dataset\")\n",
    "\n",
    "# Load the fine-tuned BERT model and its tokenizer\n",
    "model_path = \"nosql-identifier-distilbert\"\n",
    "# model = BertForSequenceClassification.from_pretrained(model_path, use_auth_token=True)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_path, num_labels=2, id2label=id2label, label2id=label2id\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# Define a function to compute metrics for evaluation\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"weighted\")\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "    }\n",
    "\n",
    "# Configure the training arguments for evaluation\n",
    "training_args = TrainingArguments(\n",
    "    per_device_eval_batch_size=8,\n",
    "    output_dir=\"test_distilbert\",  # Change this path accordingly\n",
    ")\n",
    "\n",
    "# Create the Trainer instance for evaluation\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "import csv\n",
    "fields = [\"model_name\",\"eval_loss\",\"eval_accuracy\",\"eval_precision\",\"eval_recall\",\"eval_f1\",\"eval_runtime\",\"eval_samples_per_second\",\"eval_steps_per_second\"]\n",
    "# Evaluate the BERT model on the test dataset\n",
    "evaluation_result = trainer.evaluate(tokenized_test_dataset)\n",
    "\n",
    "print(\"distilBERT model evaluation result:\", evaluation_result)\n",
    "csv_file = \"model_comparisions.csv\"\n",
    "try:\n",
    "    df = pd.read_csv(csv_file)\n",
    "except FileNotFoundError:\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "# Append the new evaluation result along with the model name to the DataFrame\n",
    "model_name = \"distil-bert\"  # Replace this with the actual model name\n",
    "evaluation_result[\"model_name\"] = model_name\n",
    "df = df.append(evaluation_result, ignore_index=True)\n",
    "\n",
    "# Save the updated DataFrame back to the CSV file\n",
    "df.to_csv(csv_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
